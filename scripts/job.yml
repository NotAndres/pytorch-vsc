apiVersion: batch/v1
kind: Job
metadata:
  name: vaejob
  namespace: 2446502gproject # Change this
spec:
  backoffLimit: 0
  template:        
    metadata:
      name: vaejob
    spec:
      containers:
      - name: vaejob-container  
        image: notandres/pytorch-custom:1.1
        command: ["python3", "/nfs/vae.py"]
        args: ["--base_dir", "$(BASE_DIR)", "--dataset_dir", "$(DATASET_DIR)", "--beta", "$(BETA)", "--epochs", "$(EPOCHS)", "--parallel", "$(PARALLEL)", "--num_workers", "$(NUM_WORKERS)"]
        resources:
          requests:
            cpu: "4000m" 
            memory: "8Gi"
            nvidia.com/gpu: 2 
          limits:
            cpu: "4000m" 
            memory: "16Gi"
            nvidia.com/gpu: 2 
        volumeMounts:
        - mountPath: /nfs
          name: nfs-access
        env:
        - name: BASE_DIR
          value: "/nfs/runs"
        - name: DATASET_DIR
          value: "/nfs/dataset/"
        - name: BETA
          value: "1"
        - name: EPOCHS
          value: "200"
        - name: "PYTHONUNBUFFERED"
          value: "1"
        - name: "PARALLEL"
          value: "True"
        - name: "NUM_WORKERS"
          value: "4"
        - name: "BATCH_SIZE"
          value: "1024"
      volumes:
      - name: nfs-access
        persistentVolumeClaim: 
          claimName: 2446502gvol1claim # Change this
      nodeSelector:
        node-role.ida/gputitan: "true"
      restartPolicy: Never
