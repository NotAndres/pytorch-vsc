{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE and VSC for Cell Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cuda\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../Data/'\n",
    "results_dir = '../../../results/epoch100beta5e-1/'\n",
    "tensorboard_dir = '../../../tb'\n",
    "batch_size = 128\n",
    "\n",
    "tb_writer = SummaryWriter(tensorboard_dir)\n",
    "\n",
    "torch.manual_seed(22)\n",
    "device = torch.device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is a utility to load and split the data given the path where the data is stored, pytorch keeps the folder names as labes as if it was a classification task, but they can just be ignored when using the data loaders. Since the task at hand is from a very specific domain (biology and cell images) the normalization values that are often used for computer vision tasks cannot be used. The mean and std used to normalize the dataset was pre computed from a small sample of the dataset and might not be accurate, but it seems to work well right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(data_dir, n_split=0.2, batch_size=256):\n",
    "    \n",
    "    pin_memory = cuda.is_available()\n",
    "    workers = 4\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    image_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        transforms.Normalize((0.0302, 0.0660, 0.0518), (0.0633, 0.0974, 0.0766))\n",
    "    ]))\n",
    "    # Create training and validation dataloaders\n",
    "    total = len(image_dataset)\n",
    "    n_test = int(total * n_split)\n",
    "    n_train = total - n_test \n",
    "    train_set, test_set = data.random_split(image_dataset, (n_train, n_test))\n",
    "\n",
    "    n_val = int(len(train_set) * n_split)\n",
    "    n_train = len(train_set) - n_val\n",
    "    train_set, val_set = data.random_split(train_set, (n_train, n_val))  \n",
    "    \n",
    "    print('Train split: ', len(train_set))\n",
    "    print('Val split: ', len(val_set))\n",
    "    print('Test split: ', len(test_set))\n",
    "    \n",
    "    train_loader = data.DataLoader(\n",
    "      train_set,\n",
    "      batch_size=batch_size,\n",
    "      num_workers = workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=pin_memory\n",
    "    )\n",
    "    val_loader = data.DataLoader(\n",
    "      val_set,\n",
    "      batch_size=batch_size,\n",
    "      num_workers = workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=pin_memory\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "      test_set,\n",
    "      batch_size=batch_size,\n",
    "      num_workers = workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=pin_memory\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to view tensors as a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.0302, 0.0660, 0.0518])\n",
    "    std = np.array([0.0633, 0.0974, 0.0766])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_and_unnormalize(batch_tensor):\n",
    "    grid = torchvision.utils.make_grid(batch_tensor)\n",
    "    image = grid.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.0302, 0.0660, 0.0518])\n",
    "    std = np.array([0.0633, 0.0974, 0.0766])\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational AutoEncoder\n",
    "\n",
    "The previous work this is based on had an specific VAE architecture implemented in TensorFlow, the first step was to migrate that NN to Pytorch keeping the same layers and the same operations that were done in the encoder and autoencoder, as well as to keep the same loss fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        channels = 'placeholder'\n",
    "        # Encoder\n",
    "        self.encoder_conv1 = self.getConvolutionLayer(3, 128)\n",
    "        self.encoder_conv2 = self.getConvolutionLayer(128, 64)\n",
    "        self.encoder_conv3 = self.getConvolutionLayer(64, 32)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.encoder_fc1 = nn.Linear(4608, self.latent_dim)\n",
    "        self.encoder_fc2 = nn.Linear(4608, self.latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_fc1 = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 4608),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Reshape to 32x12x12\n",
    "        self.decoder_upsampler1 = nn.Upsample(scale_factor=(2,2) ,mode='nearest')\n",
    "        \n",
    "        self.decoder_deconv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Upsample(scale_factor=(2,2) ,mode='nearest')\n",
    "        )\n",
    "        # 48x48x64\n",
    "        self.decoder_deconv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Upsample(scale_factor=(2,2) ,mode='nearest')\n",
    "        )\n",
    "\n",
    "        self.decoder_conv1 = nn.Conv2d(in_channels=128, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        # 96x96x128\n",
    "        \n",
    "\n",
    "    def getConvolutionLayer(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder_conv1(x)\n",
    "        x = self.encoder_conv2(x)\n",
    "        x = self.encoder_conv3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        mu = self.encoder_fc1(x)\n",
    "        sigma = self.encoder_fc2(x)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        # Keeps shape, samples from normal dist with mean 0 and variance 1\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_fc1(z)\n",
    "        z = self.decoder_upsampler1(z.view(-1, 32, 12, 12))\n",
    "        z = self.decoder_deconv1(z)\n",
    "        z = self.decoder_deconv2(z)\n",
    "        recon = self.decoder_conv1(z)        \n",
    "        return recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I've seen MSE and KLD and somewhat incompatible depending on how the scores are aggregated. It either has to be sum or mean, choosing different aggregation techniques results in the difference between scores being too different and the NN will end up optimizing the one that has the bigger impact. Current solution is B-Vae where a B parameter is added to the KLD as to control how much importance it has in the loss function; KLD and MSE are aggregated by sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar, epoch_n=False):\n",
    "    \n",
    "    # mse = F.mse_loss(recon_x, x, reduction='mean')\n",
    "     \n",
    "    mse = torch.mean(torch.sum((x - recon_x).pow(2), dim=(1,2,3)))\n",
    "    \n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    \n",
    "    #kld = torch.mean(-0.5 * torch.sum(1 + torch.log(1e-10 + sigma.pow(2)) - mu.pow(2) - sigma.pow(2)))\n",
    "    #kld = torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), axis=1))\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) * beta\n",
    "    \n",
    "    loss = mse + kld\n",
    "    return loss, mse, kld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for the model training and testing loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_mse = 0\n",
    "    train_kld = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss, mse, kld = loss_function(recon_batch, data, mu, logvar, epoch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_batch_size = len(data)\n",
    "        train_loss += loss.item() * current_batch_size\n",
    "        train_mse += mse.item() * current_batch_size\n",
    "        train_kld += kld.item()\n",
    "\n",
    "  \n",
    "        if batch_idx % (int(len(train_loader) / 4)) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item()))\n",
    "\n",
    "    datapoints = len(train_loader.dataset)\n",
    "    avg_loss = train_loss/datapoints\n",
    "    avg_mse = train_mse/datapoints\n",
    "    avg_kld = train_kld/(beta * len(train_loader))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.8f}'.format(epoch, avg_loss))\n",
    "    print('*** Avg MSE: {:.4f}'.format(avg_mse))\n",
    "    print('*** Avg KLD: {:.8f}'.format(avg_kld * beta))\n",
    "    return avg_loss, avg_mse, avg_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_mse = 0\n",
    "    test_kld = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss, mse, kld = loss_function(recon_batch, data, mu, logvar, epoch)\n",
    "\n",
    "            current_batch_size = data.size(0)\n",
    "            test_loss += loss.item() * current_batch_size\n",
    "            test_mse += mse.item() * current_batch_size\n",
    "            test_kld += kld.item()\n",
    "\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n], recon_batch[:n]]).cpu()\n",
    "                image = grid_and_unnormalize(comparison)\n",
    "                comparison = torchvision.utils.make_grid(comparison)\n",
    "                imshow(comparison)\n",
    "                \n",
    "                tb_writer.add_image(\"Reconstruction/recon_\"+str(epoch), image, epoch, dataformats='HWC')\n",
    "                \n",
    "                plt.savefig(results_dir + 'reconstruction_' + str(epoch) + '.png')\n",
    "                plt.close()\n",
    "                #save_image(comparison, results_dir + 'reconstruction_' + str(epoch) + '.tif')\n",
    "\n",
    "    datapoints = len(test_loader.dataset)\n",
    "    test_loss /= datapoints\n",
    "    test_mse /= datapoints\n",
    "    test_kld /= (beta * len(test_loader))\n",
    "    print('====> Test set loss: {:.8f}'.format(test_loss))\n",
    "    print('*** Avg MSE: {:.8f}'.format(test_mse))\n",
    "    print('*** Avg KLD: {:.8f}'.format(test_kld))\n",
    "    return test_loss, test_mse, test_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_time_in_hours(seconds):\n",
    "    hours = seconds // 3600\n",
    "    remaining_time = seconds % 3600\n",
    "    minutes = remaining_time // 60\n",
    "    seconds = remaining_time % 60\n",
    "    \n",
    "    return hours, minutes, seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "The training of the migrated VAE starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split:  97014\n",
      "Val split:  24253\n",
      "Test split:  30316\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = split_data(data_dir=data_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder_conv1): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder_conv2): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder_conv3): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten()\n",
       "  (encoder_fc1): Linear(in_features=4608, out_features=256, bias=True)\n",
       "  (encoder_fc2): Linear(in_features=4608, out_features=256, bias=True)\n",
       "  (decoder_fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=4608, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder_upsampler1): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
       "  (decoder_deconv1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
       "  )\n",
       "  (decoder_deconv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Upsample(scale_factor=(2.0, 2.0), mode=nearest)\n",
       "  )\n",
       "  (decoder_conv1): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE(256).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/97014 (0%)]\tLoss: 45754.011719\n",
      "Train Epoch: 1 [24192/97014 (25%)]\tLoss: 16964.988281\n",
      "Train Epoch: 1 [48384/97014 (50%)]\tLoss: 14790.863281\n",
      "Train Epoch: 1 [72576/97014 (75%)]\tLoss: 16751.185547\n",
      "Train Epoch: 1 [96768/97014 (100%)]\tLoss: 12587.079102\n",
      "====> Epoch: 1 Average loss: 15893.22288399\n",
      "*** Avg MSE: 13155.7149\n",
      "*** Avg KLD: 2737.51215573\n",
      "====> Test set loss: 12978.64928268\n",
      "*** Avg MSE: 9935.98048860\n",
      "*** Avg KLD: 6077.07233244\n",
      "Time elapsed 0h 2m 8s\n",
      "Train Epoch: 2 [0/97014 (0%)]\tLoss: 11623.723633\n",
      "Train Epoch: 2 [24192/97014 (25%)]\tLoss: 12517.187500\n",
      "Train Epoch: 2 [48384/97014 (50%)]\tLoss: 12044.728516\n",
      "Train Epoch: 2 [72576/97014 (75%)]\tLoss: 13148.386719\n",
      "Train Epoch: 2 [96768/97014 (100%)]\tLoss: 11722.902344\n",
      "====> Epoch: 2 Average loss: 12458.40332718\n",
      "*** Avg MSE: 9438.9664\n",
      "*** Avg KLD: 3019.44975599\n",
      "====> Test set loss: 12212.91747972\n",
      "*** Avg MSE: 9242.76471379\n",
      "*** Avg KLD: 5931.13204924\n",
      "Time elapsed 0h 4m 16s\n",
      "Train Epoch: 3 [0/97014 (0%)]\tLoss: 12635.744141\n",
      "Train Epoch: 3 [24192/97014 (25%)]\tLoss: 12167.156250\n",
      "Train Epoch: 3 [48384/97014 (50%)]\tLoss: 11809.316406\n",
      "Train Epoch: 3 [72576/97014 (75%)]\tLoss: 11473.719727\n",
      "Train Epoch: 3 [96768/97014 (100%)]\tLoss: 11399.407227\n",
      "====> Epoch: 3 Average loss: 11806.97099519\n",
      "*** Avg MSE: 8812.8703\n",
      "*** Avg KLD: 2994.06264075\n",
      "====> Test set loss: 11622.40915513\n",
      "*** Avg MSE: 8664.53737102\n",
      "*** Avg KLD: 5905.92253418\n",
      "Time elapsed 0h 6m 30s\n",
      "Train Epoch: 4 [0/97014 (0%)]\tLoss: 12345.384766\n",
      "Train Epoch: 4 [24192/97014 (25%)]\tLoss: 11060.671875\n",
      "Train Epoch: 4 [48384/97014 (50%)]\tLoss: 11458.064453\n",
      "Train Epoch: 4 [72576/97014 (75%)]\tLoss: 10536.678711\n",
      "Train Epoch: 4 [96768/97014 (100%)]\tLoss: 10683.999023\n",
      "====> Epoch: 4 Average loss: 11270.55048267\n",
      "*** Avg MSE: 8346.2223\n",
      "*** Avg KLD: 2924.30387230\n",
      "====> Test set loss: 11078.98233941\n",
      "*** Avg MSE: 8200.35858732\n",
      "*** Avg KLD: 5748.65133635\n",
      "Time elapsed 0h 8m 46s\n",
      "Train Epoch: 5 [0/97014 (0%)]\tLoss: 10906.015625\n",
      "Train Epoch: 5 [24192/97014 (25%)]\tLoss: 12418.511719\n",
      "Train Epoch: 5 [48384/97014 (50%)]\tLoss: 9554.038086\n",
      "Train Epoch: 5 [72576/97014 (75%)]\tLoss: 11654.029297\n",
      "Train Epoch: 5 [96768/97014 (100%)]\tLoss: 9607.322266\n",
      "====> Epoch: 5 Average loss: 10783.77166657\n",
      "*** Avg MSE: 7946.9091\n",
      "*** Avg KLD: 2836.82042587\n",
      "====> Test set loss: 10650.36806030\n",
      "*** Avg MSE: 7812.75081989\n",
      "*** Avg KLD: 5666.98943000\n",
      "Time elapsed 0h 10m 59s\n",
      "Train Epoch: 6 [0/97014 (0%)]\tLoss: 9537.162109\n",
      "Train Epoch: 6 [24192/97014 (25%)]\tLoss: 11022.931641\n",
      "Train Epoch: 6 [48384/97014 (50%)]\tLoss: 10221.056641\n",
      "Train Epoch: 6 [72576/97014 (75%)]\tLoss: 11375.171875\n",
      "Train Epoch: 6 [96768/97014 (100%)]\tLoss: 10251.386719\n",
      "====> Epoch: 6 Average loss: 10398.61067634\n",
      "*** Avg MSE: 7632.2018\n",
      "*** Avg KLD: 2766.36315660\n",
      "====> Test set loss: 10267.41618345\n",
      "*** Avg MSE: 7469.08724283\n",
      "*** Avg KLD: 5587.92286056\n",
      "Time elapsed 0h 13m 18s\n",
      "Train Epoch: 7 [0/97014 (0%)]\tLoss: 9541.173828\n",
      "Train Epoch: 7 [24192/97014 (25%)]\tLoss: 9728.388672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-be3e70b378fb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[0msince\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0mtrain_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_mse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_kld\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m         \u001B[0mtrain_trace\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'loss'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mtrain_trace\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'mse'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_mse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-8-725bc4f6b2a7>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(epoch, train_loader)\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mtrain_mse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mtrain_kld\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    802\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    803\u001B[0m             \u001B[1;32massert\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 804\u001B[1;33m             \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    805\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    806\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    759\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    760\u001B[0m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory_thread\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_alive\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 761\u001B[1;33m                 \u001B[0msuccess\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    762\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    763\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    722\u001B[0m         \u001B[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    723\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 724\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    725\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\queue.py\u001B[0m in \u001B[0;36mget\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    177\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mremaining\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0.0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    178\u001B[0m                         \u001B[1;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 179\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnot_empty\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mremaining\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    180\u001B[0m             \u001B[0mitem\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    181\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnot_full\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    298\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    299\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 300\u001B[1;33m                     \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    301\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    302\u001B[0m                     \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_trace = {\n",
    "    'loss': [],\n",
    "    'mse': [],\n",
    "    'kld': []\n",
    "}\n",
    "\n",
    "val_trace = {\n",
    "    'loss': [],\n",
    "    'mse': [],\n",
    "    'kld': []\n",
    "}\n",
    "epochs = 100\n",
    "beta = 0.5\n",
    "since = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_mse, train_kld = train(epoch, train_data)\n",
    "        train_trace['loss'].append(train_loss)\n",
    "        train_trace['mse'].append(train_mse)\n",
    "        train_trace['kld'].append(train_kld)\n",
    "\n",
    "        val_loss, val_mse, val_kld = test(epoch, val_data)\n",
    "        val_trace['loss'].append(val_loss)\n",
    "        val_trace['mse'].append(val_mse)\n",
    "        val_trace['kld'].append(val_kld)\n",
    "        \n",
    "        tb_writer.add_scalars('Loss/Total', {\n",
    "            'train': train_loss,\n",
    "            'test': val_loss\n",
    "        }, epoch)\n",
    "        \n",
    "        tb_writer.add_scalars('Loss/MSE', {\n",
    "            'train': train_mse,\n",
    "            'test': val_mse\n",
    "        }, epoch)\n",
    "        \n",
    "        tb_writer.add_scalars('Loss/KLD', {\n",
    "            'train': train_kld,\n",
    "            'test': val_kld\n",
    "        }, epoch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(4, 256).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            image = grid_and_unnormalize(sample)\n",
    "            sample = torchvision.utils.make_grid(sample)\n",
    "            tb_writer.add_image(\"Sample/sample_\"+str(epoch), image, epoch, dataformats='HWC')\n",
    "            imshow(sample)\n",
    "            plt.savefig(results_dir + 'sample_' + str(epoch) + '.png')\n",
    "            plt.close()\n",
    "            #save_image(sample, results_dir + 'sample_' + str(epoch) + '.tif')\n",
    "        \n",
    "        epoch_time = time.time() - since\n",
    "        e_hours, e_minutes, e_seconds = get_time_in_hours(epoch_time)\n",
    "        print('Time elapsed {:.0f}h {:.0f}m {:.0f}s'.format(e_hours, e_minutes, e_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(train_data, val_data, epochs, xlabel, ylabel, title):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    min_train = int(min(train_data))\n",
    "    max_train = int(max(train_data))\n",
    "    min_val = int(min(val_data))\n",
    "    max_val = int(max(val_data))\n",
    "    \n",
    "    low_bound = min(min_train, min_val)\n",
    "    up_bound = max(max_train, max_val)\n",
    "    \n",
    "    plt.plot(train_data, label='train')\n",
    "    plt.plot(val_data, label='test')\n",
    "    plt.xticks(np.arange(0, epochs+1, int(epochs/20)))\n",
    "    plt.yticks(np.arange(low_bound, up_bound*1.01, int((1.1*up_bound - 1.1*low_bound) / 20)))\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss(train_trace['loss'], val_trace['loss'], epochs, 'Epochs', \"Loss (MSE + KLD)\", \"Average Loss for Beta \" + str(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss(train_trace['mse'], val_trace['mse'], epochs, 'Epochs', \"MSE\", \"Average MSE for Beta \" + str(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss(train_trace['kld'], val_trace['kld'], epochs, 'Epochs', \"KLD\", \"Average KLD for Beta \" + str(beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Cells\n",
    "Please ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img, _ = next(iter(val_data))\n",
    "print(img.shape)\n",
    "print(torch.max(img[0]))\n",
    "print(torch.max(img[0][0]))\n",
    "print(torch.max(img[0][1]))\n",
    "print(torch.max(img[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = img[0:100].to(device)\n",
    "recon, mu, logvar = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img[1:2] + img[2:3]*0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interpolated = None\n",
    "base_a = None\n",
    "base_b = None\n",
    "with torch.no_grad():\n",
    "    cell_a = img[48:49].to(device)\n",
    "    cell_b = img[50:51].to(device)\n",
    "\n",
    "    mu_a, sigma_a = model.encode(cell_a)\n",
    "    mu_b, sigma_b = model.encode(cell_b)\n",
    "\n",
    "    z_a = model.reparameterize(mu_a, sigma_a)\n",
    "    z_b = model.reparameterize(mu_b, sigma_b)\n",
    "\n",
    "    z_diff = z_b - z_a\n",
    "    recon_a = model.decode(z_a)\n",
    "    recon_25 = model.decode(z_a + (z_diff * 0.25))\n",
    "    recon_50 = model.decode(z_a + (z_diff * 0.50))\n",
    "    recon_75 = model.decode(z_a + (z_diff * 0.75))\n",
    "    recon_b = model.decode(z_b)\n",
    "    interpolated = torch.cat((recon_a, recon_25, recon_50, recon_75, recon_b), dim=0).cpu()\n",
    "    base_a = cell_a.cpu()\n",
    "    base_b = cell_b.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(torch.cat((base_a, base_b), dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(interpolated))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss, mse, kld = loss_function(recon, x, mu, logvar)\n",
    "kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.mean((-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.sum(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MSE\n",
    "torch.mean(torch.mean((x - recon).pow(2), dim=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mean of sum of squared errors\n",
    "torch.mean(torch.sum((x - recon).pow(2), dim=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.sum((x - recon).pow(2), dim=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "F.mse_loss(recon, x, reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "The cell below calculates the MEAN and STD of the data set so it can be normalized properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]))\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    image_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "for dat, _ in loader:\n",
    "    batch_samples = dat.size(0)\n",
    "    dat = dat.view(batch_samples, dat.size(1), -1)\n",
    "    mean += dat.mean(2).sum(0)\n",
    "    std += dat.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "print(\"mean: \", mean)\n",
    "print(\"std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}