{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VAE and VSC for Cell Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cuda\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = '../../../Data/'\n",
    "results_dir = '../../../results/epoch100beta5e-1/'\n",
    "batch_size = 128\n",
    "\n",
    "torch.manual_seed(22)\n",
    "device = torch.device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code is a utility to load and split the data given the path where the data is stored, pytorch keeps the folder names as labes as if it was a classification task, but they can just be ignored when using the data loaders. Since the task at hand is from a very specific domain (biology and cell images) the normalization values that are often used for computer vision tasks cannot be used. The mean and std used to normalize the dataset was pre computed from a small sample of the dataset and might not be accurate, but it seems to work well right now"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(data_dir, n_split=0.2, batch_size=256):\n",
    "    \n",
    "    pin_memory = cuda.is_available()\n",
    "    workers = 0 if cuda.is_available() else 4\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    image_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        transforms.Normalize((0.0302, 0.0660, 0.0518), (0.0633, 0.0974, 0.0766))\n",
    "    ]))\n",
    "    # Create training and validation dataloaders\n",
    "    total = len(image_dataset)\n",
    "    n_test = int(total * n_split)\n",
    "    n_train = total - n_test \n",
    "    train_set, test_set = data.random_split(image_dataset, (n_train, n_test))\n",
    "\n",
    "    n_val = int(len(train_set) * n_split)\n",
    "    n_train = len(train_set) - n_val\n",
    "    train_set, val_set = data.random_split(train_set, (n_train, n_val))  \n",
    "    \n",
    "    print('Train split: ', len(train_set))\n",
    "    print('Val split: ', len(val_set))\n",
    "    print('Test split: ', len(test_set))\n",
    "    \n",
    "    train_loader = data.DataLoader(\n",
    "      train_set,\n",
    "      batch_size=batch_size,\n",
    "      num_workers = workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=pin_memory\n",
    "    )\n",
    "    val_loader = data.DataLoader(\n",
    "      val_set,\n",
    "      batch_size=batch_size,\n",
    "      num_workers = workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=pin_memory\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "      test_set,\n",
    "      batch_size=batch_size,\n",
    "      num_workers = workers,\n",
    "      shuffle=True,\n",
    "      pin_memory=pin_memory\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper function to view tensors as a plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.0302, 0.0660, 0.0518])\n",
    "    std = np.array([0.0633, 0.0974, 0.0766])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variational AutoEncoder\n",
    "\n",
    "The previous work this is based on had an specific VAE architecture implemented in TensorFlow, the first step was to migrate that NN to Pytorch keeping the same layers and the same operations that were done in the encoder and autoencoder, as well as to keep the same loss fuction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        channels = 'placeholder'\n",
    "        # Encoder\n",
    "        self.encoder_conv1 = self.getConvolutionLayer(3, 128)\n",
    "        self.encoder_conv2 = self.getConvolutionLayer(128, 64)\n",
    "        self.encoder_conv3 = self.getConvolutionLayer(64, 32)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.encoder_fc1 = nn.Linear(4608, self.latent_dim)\n",
    "        self.encoder_fc2 = nn.Linear(4608, self.latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_fc1 = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 4608),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Reshape to 32x12x12\n",
    "        self.decoder_upsampler1 = nn.Upsample(scale_factor=(2,2) ,mode='nearest')\n",
    "        \n",
    "        self.decoder_deconv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Upsample(scale_factor=(2,2) ,mode='nearest')\n",
    "        )\n",
    "        # 48x48x64\n",
    "        self.decoder_deconv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Upsample(scale_factor=(2,2) ,mode='nearest')\n",
    "        )\n",
    "\n",
    "        self.decoder_conv1 = nn.Conv2d(in_channels=128, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        # 96x96x128\n",
    "        \n",
    "\n",
    "    def getConvolutionLayer(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder_conv1(x)\n",
    "        x = self.encoder_conv2(x)\n",
    "        x = self.encoder_conv3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        mu = self.encoder_fc1(x)\n",
    "        sigma = self.encoder_fc2(x)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        # Keeps shape, samples from normal dist with mean 0 and variance 1\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_fc1(z)\n",
    "        z = self.decoder_upsampler1(z.view(-1, 32, 12, 12))\n",
    "        z = self.decoder_deconv1(z)\n",
    "        z = self.decoder_deconv2(z)\n",
    "        recon = self.decoder_conv1(z)        \n",
    "        return recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From what I've seen MSE and KLD and somewhat incompatible depending on how the scores are aggregated. It either has to be sum or mean, choosing different aggregation techniques results in the difference between scores being too different and the NN will end up optimizing the one that has the bigger impact. Current solution is B-Vae where a B parameter is added to the KLD as to control how much importance it has in the loss function; KLD and MSE are aggregated by sum."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar, epoch_n=False):\n",
    "    \n",
    "    # mse = F.mse_loss(recon_x, x, reduction='mean')\n",
    "     \n",
    "    mse = torch.mean(torch.sum((x - recon_x).pow(2), dim=(1,2,3)))\n",
    "    \n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    \n",
    "    #kld = torch.mean(-0.5 * torch.sum(1 + torch.log(1e-10 + sigma.pow(2)) - mu.pow(2) - sigma.pow(2)))\n",
    "    #kld = torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), axis=1))\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) * beta\n",
    "    \n",
    "    loss = mse + kld\n",
    "    return loss, mse, kld"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helpers for the model training and testing loop "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(epoch, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_mse = 0\n",
    "    train_kld = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss, mse, kld = loss_function(recon_batch, data, mu, logvar, epoch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_batch_size = len(data)\n",
    "        train_loss += loss.item() * current_batch_size\n",
    "        train_mse += mse.item() * current_batch_size\n",
    "        train_kld += kld.item()\n",
    "\n",
    "  \n",
    "        if batch_idx % (int(len(train_loader) / 4)) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item()))\n",
    "\n",
    "    datapoints = len(train_loader.dataset)\n",
    "    avg_loss = train_loss/datapoints\n",
    "    avg_mse = train_mse/datapoints\n",
    "    avg_kld = train_kld/(beta * len(train_loader))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.8f}'.format(epoch, avg_loss))\n",
    "    print('*** Avg MSE: {:.4f}'.format(avg_mse))\n",
    "    print('*** Avg KLD: {:.8f}'.format(avg_kld * beta))\n",
    "    return avg_loss, avg_mse, avg_kld"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(epoch, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_mse = 0\n",
    "    test_kld = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss, mse, kld = loss_function(recon_batch, data, mu, logvar, epoch)\n",
    "\n",
    "            current_batch_size = data.size(0)\n",
    "            test_loss += loss.item() * current_batch_size\n",
    "            test_mse += mse.item() * current_batch_size\n",
    "            test_kld += kld.item()\n",
    "\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n], recon_batch[:n]]).cpu()\n",
    "                comparison = torchvision.utils.make_grid(comparison)\n",
    "                imshow(comparison)\n",
    "                plt.savefig(results_dir + 'reconstruction_' + str(epoch) + '.png')\n",
    "                plt.close()\n",
    "                #save_image(comparison, results_dir + 'reconstruction_' + str(epoch) + '.tif')\n",
    "\n",
    "    datapoints = len(test_loader.dataset)\n",
    "    test_loss /= datapoints\n",
    "    test_mse /= datapoints\n",
    "    test_kld /= (beta * len(test_loader))\n",
    "    print('====> Test set loss: {:.8f}'.format(test_loss))\n",
    "    print('*** Avg MSE: {:.8f}'.format(test_mse))\n",
    "    print('*** Avg KLD: {:.8f}'.format(test_kld))\n",
    "    return test_loss, test_mse, test_kld"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_time_in_hours(seconds):\n",
    "    hours = seconds // 3600\n",
    "    remaining_time = seconds % 3600\n",
    "    minutes = remaining_time // 60\n",
    "    seconds = remaining_time % 60\n",
    "    \n",
    "    return hours, minutes, seconds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "The training of the migrated VAE starts here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_data(data_dir=data_dir, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = VAE(256).to(device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_trace = {\n",
    "    'loss': [],\n",
    "    'mse': [],\n",
    "    'kld': []\n",
    "}\n",
    "\n",
    "val_trace = {\n",
    "    'loss': [],\n",
    "    'mse': [],\n",
    "    'kld': []\n",
    "}\n",
    "epochs = 100\n",
    "beta = 0.5\n",
    "since = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "        loss, mse, kld = train(epoch, train_data)\n",
    "        train_trace['loss'].append(loss)\n",
    "        train_trace['mse'].append(mse)\n",
    "        train_trace['kld'].append(kld)\n",
    "\n",
    "        loss, mse, kld = test(epoch, val_data)\n",
    "        val_trace['loss'].append(loss)\n",
    "        val_trace['mse'].append(mse)\n",
    "        val_trace['kld'].append(kld)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(4, 256).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            sample = torchvision.utils.make_grid(sample)\n",
    "            imshow(sample)\n",
    "            plt.savefig(results_dir + 'sample_' + str(epoch) + '.png')\n",
    "            plt.close()\n",
    "            #save_image(sample, results_dir + 'sample_' + str(epoch) + '.tif')\n",
    "        \n",
    "        epoch_time = time.time() - since\n",
    "        e_hours, e_minutes, e_seconds = get_time_in_hours(epoch_time)\n",
    "        print('Time elapsed {:.0f}h {:.0f}m {:.0f}s'.format(e_hours, e_minutes, e_seconds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(train_data, val_data, epochs, xlabel, ylabel, title):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    min_train = int(min(train_data))\n",
    "    max_train = int(max(train_data))\n",
    "    min_val = int(min(val_data))\n",
    "    max_val = int(max(val_data))\n",
    "    \n",
    "    low_bound = min(min_train, min_val)\n",
    "    up_bound = max(max_train, max_val)\n",
    "    \n",
    "    plt.plot(train_data, label='train')\n",
    "    plt.plot(val_data, label='test')\n",
    "    plt.xticks(np.arange(0, epochs+1, int(epochs/20)))\n",
    "    plt.yticks(np.arange(low_bound, up_bound*1.01, int((1.1*up_bound - 1.1*low_bound) / 20)))\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(train_trace['loss'], val_trace['loss'], epochs, 'Epochs', \"Loss (MSE + KLD)\", \"Average Loss for Beta \" + str(beta))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(train_trace['mse'], val_trace['mse'], epochs, 'Epochs', \"MSE\", \"Average MSE for Beta \" + str(beta))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(train_trace['kld'], val_trace['kld'], epochs, 'Epochs', \"KLD\", \"Average KLD for Beta \" + str(beta))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experimental Cells\n",
    "Please ignore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img, _ = next(iter(val_data))\n",
    "print(img.shape)\n",
    "print(torch.max(img[0]))\n",
    "print(torch.max(img[0][0]))\n",
    "print(torch.max(img[0][1]))\n",
    "print(torch.max(img[0][2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = img[0:100].to(device)\n",
    "recon, mu, logvar = model.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img[1:2] + img[2:3]*0.25"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interpolated = None\n",
    "base_a = None\n",
    "base_b = None\n",
    "with torch.no_grad():\n",
    "    cell_a = img[48:49].to(device)\n",
    "    cell_b = img[50:51].to(device)\n",
    "\n",
    "    mu_a, sigma_a = model.encode(cell_a)\n",
    "    mu_b, sigma_b = model.encode(cell_b)\n",
    "\n",
    "    z_a = model.reparameterize(mu_a, sigma_a)\n",
    "    z_b = model.reparameterize(mu_b, sigma_b)\n",
    "\n",
    "    z_diff = z_b - z_a\n",
    "    recon_a = model.decode(z_a)\n",
    "    recon_25 = model.decode(z_a + (z_diff * 0.25))\n",
    "    recon_50 = model.decode(z_a + (z_diff * 0.50))\n",
    "    recon_75 = model.decode(z_a + (z_diff * 0.75))\n",
    "    recon_b = model.decode(z_b)\n",
    "    interpolated = torch.cat((recon_a, recon_25, recon_50, recon_75, recon_b), dim=0).cpu()\n",
    "    base_a = cell_a.cpu()\n",
    "    base_b = cell_b.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(torch.cat((base_a, base_b), dim=0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(interpolated))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, mse, kld = loss_function(recon, x, mu, logvar)\n",
    "kld"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.mean((-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.sum(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MSE\n",
    "torch.mean(torch.mean((x - recon).pow(2), dim=(1,2,3)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean of sum of squared errors\n",
    "torch.mean(torch.sum((x - recon).pow(2), dim=(1,2,3)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.sum((x - recon).pow(2), dim=(1,2,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "F.mse_loss(recon, x, reduction='sum')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra\n",
    "\n",
    "The cell below calculates the MEAN and STD of the data set so it can be normalized properly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]))\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    image_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "for dat, _ in loader:\n",
    "    batch_samples = dat.size(0)\n",
    "    dat = dat.view(batch_samples, dat.size(1), -1)\n",
    "    mean += dat.mean(2).sum(0)\n",
    "    std += dat.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "print(\"mean: \", mean)\n",
    "print(\"std: \", std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}